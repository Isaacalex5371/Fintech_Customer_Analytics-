import pandas as pd
from sqlalchemy import create_engine, text
import os
from dotenv import load_dotenv  # Import this

# Load environment variables from .env file
load_dotenv()

# Get the secure URL
DB_CONNECTION_STR = os.getenv("DATABASE_URL")

if not DB_CONNECTION_STR:
    raise ValueError("DATABASE_URL not found in .env file. Please check your configuration.")

CSV_PATH = os.path.join("data", "sentiment_analysis.csv")
SCHEMA_PATH = "schema.sql"

def create_schema(engine):
    
    schema_sql = """
    DROP TABLE IF EXISTS reviews;
    DROP TABLE IF EXISTS banks;

    CREATE TABLE banks (
        bank_id SERIAL PRIMARY KEY,
        bank_name VARCHAR(100) UNIQUE NOT NULL,
        app_name VARCHAR(100)
    );

    CREATE TABLE reviews (
        review_id SERIAL PRIMARY KEY,
        bank_id INTEGER REFERENCES banks(bank_id),
        review_text TEXT,
        rating INTEGER,
        review_date DATE,
        sentiment_label VARCHAR(20),
        sentiment_score FLOAT,
        source VARCHAR(50)
    );
    """
    with engine.connect() as conn:
        conn.execute(text(schema_sql))
        conn.commit()
    print("Schema created successfully.")

def populate_data(engine):
    
    if not os.path.exists(CSV_PATH):
        print("Run analysis.py first to generate the CSV!")
        return

    df = pd.read_csv(CSV_PATH)
    
    # 1. Populate Banks Table
    unique_banks = df[['bank_name']].drop_duplicates()
    # Assign app names based on bank (Hardcoded for simplicity/accuracy)
    app_map = {
        'CBE': 'Commercial Bank of Ethiopia Mobile',
        'BOA': 'BoA Mobile',
        'Dashen': 'Dashen SuperApp'
    }
    unique_banks['app_name'] = unique_banks['bank_name'].map(app_map)
    
    print("Inserting Banks...")
    unique_banks.to_sql('banks', engine, if_exists='append', index=False)
    
    # 2. Get Bank IDs back to map them for Reviews table
    # We read the banks table we just filled to get the assigned IDs
    banks_db = pd.read_sql("SELECT * FROM banks", engine)
    bank_id_map = dict(zip(banks_db['bank_name'], banks_db['bank_id']))
    
    # 3. Prepare Reviews Table
    df['bank_id'] = df['bank_name'].map(bank_id_map)
    
    # Select columns matching the table schema
    cols = ['bank_id', 'review_text', 'rating', 'review_date', 
            'sentiment_label', 'sentiment_score', 'source']
    
    # Ensure source column exists
    if 'source' not in df.columns:
        df['source'] = 'Google Play'
        
    print(f"Inserting {len(df)} reviews...")
    df[cols].to_sql('reviews', engine, if_exists='append', index=False)
    print("Data insertion complete!")

def verify_data(engine):
    
    print("\n--- Data Verification ---")
    with engine.connect() as conn:
        # KPI: Count reviews per bank
        result = conn.execute(text("""
            SELECT b.bank_name, COUNT(r.review_id) 
            FROM reviews r 
            JOIN banks b ON r.bank_id = b.bank_id 
            GROUP BY b.bank_name;
        """))
        print("\nReview Counts per Bank:")
        for row in result:
            print(f"{row[0]}: {row[1]}")

if __name__ == "__main__":
    try:
        engine = create_engine(DB_CONNECTION_STR)
        create_schema(engine)
        populate_data(engine)
        verify_data(engine)
        
        # Save schema for Rubric (Documentation)
        with open(SCHEMA_PATH, "w") as f:
            f.write("-- SQL Dump generated by src/storage.py\n")
            # (We already defined the SQL in create_schema, just saving a dummy file for the repo requirement)
            f.write("CREATE TABLE banks (...); CREATE TABLE reviews (...);")
            
    except Exception as e:
        print(f"Database Error: {e}")
        print("Tip: Check your password in DB_CONNECTION_STR")